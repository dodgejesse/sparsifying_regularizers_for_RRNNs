gpu_id=1
num_cpu=1
export CUDA_VISIBLE_DEVICES=${gpu_id}
export OMP_NUM_THREADS=${num_cpu}

hidden_size="8"
d=8
lr=1.0
lr_decay=0.98
lr_decay_epoch=150
activation="tanh"
batch_size=32
model="rrnn"
pattern="1-gram"
depth=1
input_dropout=0.0
output_dropout=0.0
dropout=0.0
rnn_dropout=0.0
use_output_gate=True
unroll_size=35
use_rho=False
max_epoch=300
weight_decay=1e-5
patience=30
gpu=True
semiring="max_plus"

~/bin/python3.6 train_lm.py --train data/train --dev data/dev --test data/test \
--hidden_size=$hidden_size \
--d=$d \
--lr=$lr \
--lr_decay=$lr_decay \
--lr_decay_epoch=$lr_decay_epoch \
--activation=$activation \
--batch_size=$batch_size \
--model=$model \
--pattern=$pattern \
--depth=$depth \
--input_dropout=$input_dropout \
--output_dropout=$output_dropout \
--dropout=$dropout \
--rnn_dropout=$rnn_dropout \
--use_output_gate=$use_output_gate \
--unroll_size=$unroll_size \
--use_rho=$use_rho \
--max_epoch=$max_epoch \
--weight_decay=$weight_decay \
--patience=$patience \
--semiring=$semiring \
--gpu=$gpu \
# > log/${hidden_size}.${depth}.${input_dropout}.${output_dropout}.${dropout}.${lr}.${lr_decay}.${lr_decay_epoch} &
